{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(rc={\n",
    "       \"figure.figsize\": (16, 10),\n",
    "       \"axes.titlesize\": 14})\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "from os.path import expanduser\n",
    "sys.path.insert(1, '{}/datsci'.format(expanduser('~')))\n",
    "from datsci import eda\n",
    "from datsci import kaggle as kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "kfood_data_file = 'data/kfood.txt'\n",
    "kfood_data_file_raw = 'data/kfood.raw.txt'\n",
    "\n",
    "catpat = re.compile(r'/(\\w+)\\.\\d+\\.jpg$')\n",
    "\n",
    "def encode_category(df):\n",
    "    # Encode categories as numerical index\n",
    "    categories = sorted(set(df.category))\n",
    "    cat2idx = {c: i for i, c  in enumerate(categories)}\n",
    "    df['category'] = df.category.apply(lambda c: cat2idx[c])\n",
    "    return categories\n",
    "\n",
    "def load_data():\n",
    "    if os.path.exists(kfood_data_file):\n",
    "\tdf = pd.read_csv(kfood_data_file)\n",
    "\treturn df, df.columns[1:-1], encode_category(df)\n",
    "    \n",
    "    if not os.path.exists(kfood_data_file_raw):\n",
    "\traise ValueError(\"data files don't exist\")\n",
    "    \n",
    "    df = pd.read_csv(kfood_data_file_raw, header=None)\n",
    "    feature_cols = list(df.columns[1:])\n",
    "    for i in xrange(len(feature_cols)):\n",
    "\tfeature_cols[i] = \"feature{}\".format(i)\n",
    "    df.columns = ['filepath'] + feature_cols\n",
    "    df['category'] = df.filepath.apply(lambda _fp: catpat.search(_fp).group(1))\n",
    "    \n",
    "    df.to_csv(kfood_data_file, index=False)\n",
    "    return df, feature_cols, encode_category(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "df, feature_cols, y_cats = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "galbijjim        219\nkimbab           217\nbibimbab         214\nhotteok          210\nnangmyun         207\ndakgalbi         205\nsullungtang      193\njapchae          193\nbulgogi          183\nsamgyupsal       173\nbossam           173\ndakbokeumtang    171\njeyookbokkeum    165\nsamgyetang       158\nddukbokee        150\nlagalbi          148\njeon             134\nkimchi           127\nramen            118\nyookgyejang      112\nName: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_name = lambda c: y_cats[c]\n",
    "df.category.apply(cat_name).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3470, 2050)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          feature0     feature1     feature2     feature3     feature4  \\\ncount  3470.000000  3470.000000  3470.000000  3470.000000  3470.000000   \nmean      0.292122     0.409072     0.527338     0.205257     0.341956   \nstd       0.210247     0.310620     0.348090     0.196429     0.309863   \nmin       0.002776     0.000000     0.009342     0.000000     0.000000   \n25%       0.135991     0.177316     0.271595     0.066020     0.121058   \n50%       0.244641     0.341317     0.450077     0.147333     0.259115   \n75%       0.396790     0.555601     0.708050     0.281080     0.469292   \nmax       1.751740     2.421970     2.682040     1.811220     3.519750   \n\n          feature5     feature6     feature7     feature8     feature9  \\\ncount  3470.000000  3470.000000  3470.000000  3470.000000  3470.000000   \nmean      0.310073     0.353334     0.147180     0.258403     0.349542   \nstd       0.210036     0.244919     0.178285     0.235923     0.232754   \nmin       0.000000     0.000308     0.000000     0.000000     0.000000   \n25%       0.153744     0.167188     0.030914     0.099226     0.177341   \n50%       0.264241     0.306355     0.088157     0.200229     0.303941   \n75%       0.423061     0.481400     0.195765     0.353510     0.470009   \nmax       1.545300     1.675310     1.987440     3.020950     1.754930   \n\n          ...       feature2039  feature2040  feature2041  feature2042  \\\ncount     ...       3470.000000  3470.000000  3470.000000  3470.000000   \nmean      ...          0.233291     0.458178     0.194507     0.187223   \nstd       ...          0.220348     0.317239     0.237958     0.198938   \nmin       ...          0.000000     0.000000     0.000000     0.000000   \n25%       ...          0.068545     0.222974     0.035571     0.043649   \n50%       ...          0.170341     0.395942     0.111097     0.124872   \n75%       ...          0.332915     0.625722     0.263321     0.263424   \nmax       ...          1.746170     2.017150     2.214680     1.512200   \n\n       feature2043  feature2044  feature2045  feature2046  feature2047  \\\ncount  3470.000000  3470.000000  3470.000000  3470.000000  3470.000000   \nmean      0.272237     0.580906     0.785038     0.943039     0.223918   \nstd       0.263337     0.417334     0.550332     0.555256     0.208564   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.075874     0.256956     0.336011     0.507198     0.067607   \n50%       0.194520     0.500477     0.682529     0.866596     0.164583   \n75%       0.385894     0.826897     1.125905     1.315900     0.327013   \nmax       1.982610     2.477140     3.101890     3.074130     1.591410   \n\n          category  \ncount  3470.000000  \nmean      9.043228  \nstd       5.724166  \nmin       0.000000  \n25%       4.000000  \n50%       9.000000  \n75%      14.000000  \nmax      19.000000  \n\n[8 rows x 2049 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110fd2d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x110fd26d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[feature_cols[:5]].describe().ix[1:,].plot(kind='bar', figsize=(10,3), title=\"First five features\".title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "target_col = 'category'\n",
    "X_all = df[feature_cols]  # feature values for all students\n",
    "y_all = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3470, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3470,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split up the train and test data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "test_size=0.3 # 30 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=test_size, random_state=0, stratify=y_all)\n",
    "\n",
    "# Split up the filepaths for comparison (maybe useful later)\n",
    "X_train_filepath, X_test_filepath = train_test_split(df['filepath'], test_size=test_size, random_state=0, stratify=y_all)\n",
    "\n",
    "# Test to see that the train_test_split splits the filepaths the same way as the feature data\n",
    "np.array_equal(pd.merge(pd.DataFrame(X_train_filepath, columns=['filepath']), df, how='left', on='filepath')[feature_cols].values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2431, 2048), (1039, 2048))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2431,), (1039,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42739613327848625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1039./2431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               train  test  test_perc\nbibimbab         150    64   0.299065\nbossam           121    52   0.300578\nbulgogi          128    55   0.300546\ndakbokeumtang    120    51   0.298246\ndakgalbi         144    61   0.297561\nddukbokee        105    45   0.300000\ngalbijjim        153    66   0.301370\nhotteok          147    63   0.300000\njapchae          135    58   0.300518\njeon              94    40   0.298507\njeyookbokkeum    116    49   0.296970\nkimbab           152    65   0.299539\nkimchi            89    38   0.299213\nlagalbi          104    44   0.297297\nnangmyun         145    62   0.299517\nramen             83    35   0.296610\nsamgyetang       111    47   0.297468\nsamgyupsal       121    52   0.300578\nsullungtang      135    58   0.300518\nyookgyejang       78    34   0.303571"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_counts_df = pd.concat([y_train.apply(cat_name).value_counts(), y_test.apply(cat_name).value_counts()], axis=1)\n",
    "split_counts_df.columns = ['train', 'test']\n",
    "split_counts_df['test_perc'] = split_counts_df.apply(lambda row: float(row.test) / row.sum(), axis=1)\n",
    "split_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Classifiers to try in Sklearn:\n",
    "\n",
    "- SVC\n",
    "- KNeighborsClassifier\n",
    "- RandomForestClassifier\n",
    "- LogisticRegression\n",
    "- GradientBoostingClassifier\n",
    "- AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test, description):\n",
    "    results = {'description': description}\n",
    "    \n",
    "    # Train\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    results['time_train'] = end - start\n",
    "\n",
    "    # Predict train\n",
    "    start = time.time()\n",
    "    y_hat = clf.predict(X_train)\n",
    "    end = time.time()\n",
    "    results['f1_score_train'] = f1_score(y_train.values, y_hat, average='micro')\n",
    "    results['time_predict_train'] = end - start\n",
    "\n",
    "    # Predict test\n",
    "    start = time.time()\n",
    "    y_hat = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    results['f1_score_test'] = f1_score(y_test.values, y_hat, average='micro')\n",
    "    results['time_predict_test'] = end - start\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=1.0, kernel='linear', gamma='auto')\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC linear kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='poly', degree=2, gamma='auto')\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC polynomial deg 2 kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='poly', degree=3, gamma='auto')\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC polynomial deg 3 kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='auto')\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC rbf kernel, one-vs-one\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='linear', gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC linear kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='poly', degree=2, gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC linear poly deg 2 kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='poly', degree=3, gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC linear poly deg 3 kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='rbf', gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC rbf kernel, one-vs-rest\"))\n",
    "\n",
    "# K-Neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "clf = KNC(n_neighbors=3, weights='uniform')\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"KNeighbors, 3 neighbors\"))\n",
    "\n",
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "clf = RFC(n_estimators=10, max_depth=None, min_samples_split=2, n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"RandomForest, 10 estimators\"))\n",
    "\n",
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty='l2', random_state=0, multi_class='ovr', n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"LogisticRegression ovr\"))\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', random_state=0, multi_class='multinomial', solver='lbfgs', n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"LogisticRegression multinomial\"))\n",
    "\n",
    "# Tried boosting, but not such great results, so exclude from further analysis\n",
    "# # GradientBoostingClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "# clf = GBC(loss='deviance', learning_rate=0.1, n_estimators=100, max_depth=None, min_samples_split=2)\n",
    "# results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"GradientBoostingClassifier\"))\n",
    "\n",
    "# # AdaBoostClassifier\n",
    "# from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "# clf = ABC(SVC(C=1.0, kernel='linear', gamma='auto'), n_estimators=100, learning_rate=1.0, algorithm='SAMME')\n",
    "#results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"AdaBoostClassifier w SVC linear kernel\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Results using f1_score with average='micro':\n",
    "\n",
    "                              description   f1_score_test  f1_score_train  time_predict_test  time_predict_train    time_train\n",
    "            SVC linear kernel, one-vs-one        0.794995        1.000000           3.811647            8.710620      6.530875\n",
    "  SVC polynomial deg 2 kernel, one-vs-one        0.271415        0.266557           4.560238           10.932422     19.331461\n",
    "  SVC polynomial deg 3 kernel, one-vs-one        0.064485        0.063348           4.647615           10.951944     19.621503\n",
    "               SVC rbf kernel, one-vs-one        0.704524        0.763472           4.424742           10.265058     12.673358\n",
    "           SVC linear kernel, one-vs-rest        0.769971        1.000000           9.859875           23.225768     14.141236\n",
    "SVC linear poly deg 2 kernel, one-vs-rest        0.721848        0.839572          12.610308           29.113087     16.113646\n",
    "SVC linear poly deg 3 kernel, one-vs-rest        0.726660        0.868367          12.953984           30.955226     17.060905\n",
    "              SVC rbf kernel, one-vs-rest        0.730510        0.830111          11.662916           27.549705     15.683099\n",
    "                  KNeighbors, 3 neighbors        0.619827        0.815714           7.049512           16.117123      0.267269\n",
    "              RandomForest, 10 estimators        0.457170        0.995475           0.015634            0.022134      0.934990\n",
    "               GradientBoostingClassifier        0.448508        1.000000           0.111043            0.270002   2495.067427\n",
    "   AdaBoostClassifier w SVC linear kernel        0.678537        0.781160         463.121845         1087.314692   2854.012287\n",
    "                   LogisticRegression ovr        0.793070        1.000000           0.009143            0.015798     16.777627\n",
    "           LogisticRegression multinomial        0.803657        1.000000           0.004691            0.009141      1.540244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# Re-run using just simple accuracy scores, in order to compare with retrain code in tensorflow/examples/image_retraining\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_predict2(clf, X_train, y_train, X_test, y_test, description):\n",
    "    results = {'description': description}\n",
    "    \n",
    "    # Train\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    results['time_train'] = end - start\n",
    "\n",
    "    # Predict train\n",
    "    start = time.time()\n",
    "    y_hat = clf.predict(X_train)\n",
    "    end = time.time()\n",
    "    results['accuracy_train'] = accuracy_score(y_train.values, y_hat)\n",
    "    results['time_predict_train'] = end - start\n",
    "\n",
    "    # Predict test\n",
    "    start = time.time()\n",
    "    y_hat = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    results['accuracy_test'] = accuracy_score(y_test.values, y_hat)\n",
    "    results['time_predict_test'] = end - start\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=1.0, kernel='linear', gamma='auto')\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC linear kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='poly', degree=2, gamma='auto')\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC polynomial deg 2 kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='poly', degree=3, gamma='auto')\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC polynomial deg 3 kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='auto')\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC rbf kernel, one-vs-one\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='linear', gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC linear kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='poly', degree=2, gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC linear poly deg 2 kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='poly', degree=3, gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC linear poly deg 3 kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='rbf', gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC rbf kernel, one-vs-rest\"))\n",
    "\n",
    "# K-Neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "clf = KNC(n_neighbors=3, weights='uniform')\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"KNeighbors, 3 neighbors\"))\n",
    "\n",
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "clf = RFC(n_estimators=10, max_depth=None, min_samples_split=2, n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"RandomForest, 10 estimators\"))\n",
    "\n",
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty='l2', random_state=0, multi_class='ovr', n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"LogisticRegression ovr\"))\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', random_state=0, multi_class='multinomial', solver='lbfgs', n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"LogisticRegression multinomial\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_predict2(clf, X_train, y_train, X_test, y_test, description):\n",
    "    results = {'description': description}\n",
    "    \n",
    "    # Train\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    results['time_train'] = end - start\n",
    "\n",
    "    # Predict train\n",
    "    start = time.time()\n",
    "    y_hat = clf.predict(X_train)\n",
    "    end = time.time()\n",
    "    results['accuracy_train'] = accuracy_score(y_train.values, y_hat)\n",
    "    results['time_predict_train'] = end - start\n",
    "\n",
    "    # Predict test\n",
    "    start = time.time()\n",
    "    y_hat = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    results['accuracy_test'] = accuracy_score(y_test.values, y_hat)\n",
    "    results['time_predict_test'] = end - start\n",
    "\n",
    "    return results\n",
    "\n",
    "results = []\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', random_state=0, multi_class='multinomial', solver='newton-cg', n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"LogisticRegression multinomial\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy_test  accuracy_train                     description  \\\n",
      "0       0.803657               1  LogisticRegression multinomial   \n",
      "\n",
      "   time_predict_test  time_predict_train  time_train  \n",
      "0           0.008209            0.010171   10.576213  \n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "    accuracy_test  accuracy_train                                description  time_predict_test  time_predict_train  time_train\n",
    "0        0.794995        1.000000              SVC linear kernel, one-vs-one           3.966444            9.055261    6.557868 \n",
    "1        0.271415        0.266557    SVC polynomial deg 2 kernel, one-vs-one           4.838109           11.241315   20.264152 \n",
    "2        0.064485        0.063348    SVC polynomial deg 3 kernel, one-vs-one           4.709020           11.161063   20.114124 \n",
    "3        0.704524        0.763472                 SVC rbf kernel, one-vs-one           4.518843           10.798448   12.761727 \n",
    "4        0.769971        1.000000             SVC linear kernel, one-vs-rest          10.246530           24.071269   14.418401 \n",
    "5        0.721848        0.839572  SVC linear poly deg 2 kernel, one-vs-rest          12.586333           29.298426   16.180739 \n",
    "6        0.726660        0.868367  SVC linear poly deg 3 kernel, one-vs-rest          12.762013           30.456582   17.197990 \n",
    "7        0.730510        0.830111                SVC rbf kernel, one-vs-rest          11.545363           27.218193   15.499681 \n",
    "8        0.619827        0.815714                    KNeighbors, 3 neighbors           6.958227           16.025329    0.264954 \n",
    "9        0.457170        0.996709                RandomForest, 10 estimators           0.140045            0.158466    0.558396 \n",
    "10       0.793070        1.000000                     LogisticRegression ovr           0.005958            0.010534   18.181948\n",
    "11       0.803657        1.000000             LogisticRegression multinomial           0.008209            0.010171   10.576213"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Fine-tune SVC linear kernel and Logistic Regression ovr and multinomial models using logloss/cross entropy error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV as GSCV\n",
    "\n",
    "# SVC linear kernel\n",
    "clf_svc = SVC(gamma='auto')\n",
    "\n",
    "best_score = None\n",
    "best_params = None\n",
    "for i in range(3):\n",
    "    if i < 3 or i % 10 == 0:\n",
    "\tprint \"iteration {}\".format(i)\n",
    "\tstart = time.time()\n",
    "    gs_clf = GSCV(\n",
    "\tclf_svc,\n",
    "\t{'kernel':['linear', 'rbf'], 'C':[10.0, 1.0, .1, .01]},\n",
    "\tscoring='log_loss',\n",
    "\tcv=5,\n",
    "\tn_jobs=4)\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    _score = accuracy_score(y_test_binary, gs_clf.predict(X_test))\n",
    "    if best_score is None or best_score < _score:\n",
    "\tbest_score = _score\n",
    "\tbest_params = {\n",
    "\t    'C': gs_clf.best_estimator_.C,\n",
    "\t    'kernel': gs_clf.best_estimator_.kernel}\n",
    "    if i < 3:\n",
    "\tend = time.time()    \n",
    "\tprint \"Each iteration time(secs): {:.3f}\".format(end - start)\n",
    "\t\n",
    "print best_score, best_params\n",
    "\n",
    "# i in range(10)\n",
    "# {'n_estimators': [10, 15, 20], 'max_depth': [None, 2, 4, 8, 16], 'min_samples_split': [2, 4, 8, 16]}\n",
    "# 0.802721088435 {'n_estimators': 15, 'min_samples_split': 4, 'max_depth': 4}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GSCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-268388f86aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"iteration {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     gs_clf = GSCV(\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mclf_svc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m'tol'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GSCV' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression ovr\n",
    "\n",
    "clf_lr = LogisticRegression(penalty='l2', random_state=0, multi_class='ovr', n_jobs=2)\n",
    "\n",
    "best_score = None\n",
    "best_params = None\n",
    "for i in range(3):\n",
    "    if i < 3 or i % 10 == 0:\n",
    "\tprint \"iteration {}\".format(i)\n",
    "\tstart = time.time()\n",
    "    gs_clf = GSCV(\n",
    "\tclf_lr,\n",
    "\t{'tol':[0.0001, 0.001, 0.00001], 'C':[10.0, 1.0, .1, .01]},\n",
    "\tscoring='log_loss',\n",
    "\tcv=5,\n",
    "\tn_jobs=4)\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    _score = accuracy_score(y_test_binary, gs_clf.predict(X_test))\n",
    "    if best_score is None or best_score < _score:\n",
    "\tbest_score = _score\n",
    "\tbest_params = {\n",
    "\t    'C': gs_clf.best_estimator_.C,\n",
    "\t    'tol': gs_clf.best_estimator_.tol}\n",
    "    if i < 3:\n",
    "\tend = time.time()    \n",
    "\tprint \"Each iteration time(secs): {:.3f}\".format(end - start)\n",
    "\t\n",
    "print best_score, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# Logistic Regression multinomial\n",
    "\n",
    "clf_lr2 = LogisticRegression(penalty='l2', random_state=0, multi_class='multinomial', solver='lbfgs', n_jobs=2)\n",
    "    \n",
    "best_score = None\n",
    "best_params = None\n",
    "for i in range(3):\n",
    "    if i < 3 or i % 10 == 0:\n",
    "\tprint \"iteration {}\".format(i)\n",
    "\tstart = time.time()\n",
    "    gs_clf = GSCV(\n",
    "\tclf_lr2,\n",
    "\t{'tol':[0.0001, 0.001, 0.00001], 'C':[10.0, 1.0, .1, .01], 'max_iter'=[100, 50, 150]},\n",
    "\tscoring='log_loss',\n",
    "\tcv=5,\n",
    "\tn_jobs=4)\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    _score = accuracy_score(y_test_binary, gs_clf.predict(X_test))\n",
    "    if best_score is None or best_score < _score:\n",
    "\tbest_score = _score\n",
    "\tbest_params = {\n",
    "\t    'C': gs_clf.best_estimator_.C,\n",
    "\t    'max_iter': gs_clf.best_estimator_.max_iter,\n",
    "\t    'tol': gs_clf.best_estimator_.tol}\n",
    "    if i < 3:\n",
    "\tend = time.time()    \n",
    "\tprint \"Each iteration time(secs): {:.3f}\".format(end - start)\n",
    "\t\n",
    "print best_score, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Run with tensorflow retrain final layer from within `tensorflow/examples/image_retraining`\n",
    "\n",
    "```\n",
    "python retrain.py --image_dir kfood --output_graph ./kfood_graph.pb --output_labels ./kfood_output_labels.txt --how_many_training_steps 4000 --learning_rate 0.01 --testing_percentage 20 --validation_percentage 20 --train_batch_size 100 --noflip_left_right --random_crop 0 --random_scale 0 --random_brightness 0\n",
    "\n",
    "python retrain.py --image_dir kfood --output_graph ./kfood_graph.pb --output_labels ./kfood_output_labels.txt --how_many_training_steps 8000 --learning_rate 0.01 --testing_percentage 20 --validation_percentage 20 --train_batch_size 100 --noflip_left_right --random_crop 0 --random_scale 0 --random_brightness 0\n",
    "\n",
    "python retrain.py --image_dir kfood --output_graph ./kfood_graph.pb --output_labels ./kfood_output_labels.txt --how_many_training_steps 12000 --learning_rate 0.01 --testing_percentage 20 --validation_percentage 20 --train_batch_size 100 --noflip_left_right --random_crop 0 --random_scale 0 --random_brightness 0\n",
    "\n",
    "time\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Summary of results for tensorflow retraining last layer\n",
    "train_accuracy and valid_accuracy correspond only to the batch in the last training step\n",
    "\n",
    "\n",
    "training_steps learning_rate train_batch_size flip_left_right random_crop random_scale random_brightness train_accuracy valid_accuracy test_accuracy runtime\n",
    "4000           0.01          100              no              0           0            0                 92.0           73.0           76.8\n",
    "8000           0.01          100              no              0           0            0                 98.0           81.0           79.2\n",
    "12000          0.01          100              no              0           0            0                 100.0          74.0           81.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
