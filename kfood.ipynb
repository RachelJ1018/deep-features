{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(rc={\n",
    "       \"figure.figsize\": (16, 10),\n",
    "       \"axes.titlesize\": 14})\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "from os.path import expanduser\n",
    "sys.path.insert(1, '{}/datsci'.format(expanduser('~')))\n",
    "from datsci import eda\n",
    "from datsci import kaggle as kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "kfood_data_file = 'data/kfood.txt'\n",
    "kfood_data_file_raw = 'data/kfood.raw.txt'\n",
    "\n",
    "catpat = re.compile(r'/(\\w+)\\.\\d+\\.jpg$')\n",
    "\n",
    "def encode_category(df):\n",
    "    # Encode categories as numerical index\n",
    "    categories = sorted(set(df.category))\n",
    "    cat2idx = {c: i for i, c in enumerate(categories)}\n",
    "    df['category'] = df.category.apply(lambda c: cat2idx[c])\n",
    "    return categories\n",
    "\n",
    "def load_data():\n",
    "    if os.path.exists(kfood_data_file):\n",
    "\tdf = pd.read_csv(kfood_data_file)\n",
    "\treturn df, df.columns[1:-1], encode_category(df)\n",
    "    \n",
    "    if not os.path.exists(kfood_data_file_raw):\n",
    "\traise ValueError(\"data files don't exist\")\n",
    "    \n",
    "    df = pd.read_csv(kfood_data_file_raw, header=None)\n",
    "    feature_cols = list(df.columns[1:])\n",
    "    for i in xrange(len(feature_cols)):\n",
    "\tfeature_cols[i] = \"feature{}\".format(i)\n",
    "    df.columns = ['filepath'] + feature_cols\n",
    "    df['category'] = df.filepath.apply(lambda _fp: catpat.search(_fp).group(1))\n",
    "    \n",
    "    df.to_csv(kfood_data_file, index=False)\n",
    "    return df, feature_cols, encode_category(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "df, feature_cols, y_cats = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.apply(cat_name).value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "galbijjim        219\n",
       "kimbab           217\n",
       "bibimbab         214\n",
       "hotteok          210\n",
       "nangmyun         207\n",
       "dakgalbi         205\n",
       "sullungtang      193\n",
       "japchae          193\n",
       "bulgogi          183\n",
       "samgyupsal       173\n",
       "bossam           173\n",
       "dakbokeumtang    171\n",
       "jeyookbokkeum    165\n",
       "samgyetang       158\n",
       "ddukbokee        150\n",
       "lagalbi          148\n",
       "jeon             134\n",
       "kimchi           127\n",
       "ramen            118\n",
       "yookgyejang      112\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_name = lambda c: y_cats[c]\n",
    "df.category.apply(cat_name).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x111e97cd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAFMCAYAAAAugrHSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzLQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111c8b810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.category.apply(cat_name).value_counts().plot(kind='bar', title=\"Distribution of Counts for Each Label\", figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "| Name           |  Number of samples\n",
    "| ---\t\t | ---\n",
    "| galbijjim      |  219\n",
    "| kimbab         |  217\n",
    "| bibimbab       |  214\n",
    "| hotteok        |  210\n",
    "| nangmyun       |  207\n",
    "| dakgalbi       |  205\n",
    "| sullungtang    |  193\n",
    "| japchae        |  193\n",
    "| bulgogi        |  183\n",
    "| samgyupsal     |  173\n",
    "| bossam         |  173\n",
    "| dakbokeumtang  |  171\n",
    "| jeyookbokkeum  |  165\n",
    "| samgyetang     |  158\n",
    "| ddukbokee      |  150\n",
    "| lagalbi        |  148\n",
    "| jeon           |  134\n",
    "| kimchi         |  127\n",
    "| ramen          |  118\n",
    "| yookgyejang    |  112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3470, 2050)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3470.000000</td>\n",
       "      <td>3470.000000</td>\n",
       "      <td>3470.000000</td>\n",
       "      <td>3470.000000</td>\n",
       "      <td>3470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.292122</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>0.527338</td>\n",
       "      <td>0.205257</td>\n",
       "      <td>0.341956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.210247</td>\n",
       "      <td>0.310620</td>\n",
       "      <td>0.348090</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.309863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.135991</td>\n",
       "      <td>0.177316</td>\n",
       "      <td>0.271595</td>\n",
       "      <td>0.066020</td>\n",
       "      <td>0.121058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.244641</td>\n",
       "      <td>0.341317</td>\n",
       "      <td>0.450077</td>\n",
       "      <td>0.147333</td>\n",
       "      <td>0.259115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.396790</td>\n",
       "      <td>0.555601</td>\n",
       "      <td>0.708050</td>\n",
       "      <td>0.281080</td>\n",
       "      <td>0.469292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.751740</td>\n",
       "      <td>2.421970</td>\n",
       "      <td>2.682040</td>\n",
       "      <td>1.811220</td>\n",
       "      <td>3.519750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature0     feature1     feature2     feature3     feature4\n",
       "count  3470.000000  3470.000000  3470.000000  3470.000000  3470.000000\n",
       "mean      0.292122     0.409072     0.527338     0.205257     0.341956\n",
       "std       0.210247     0.310620     0.348090     0.196429     0.309863\n",
       "min       0.002776     0.000000     0.009342     0.000000     0.000000\n",
       "25%       0.135991     0.177316     0.271595     0.066020     0.121058\n",
       "50%       0.244641     0.341317     0.450077     0.147333     0.259115\n",
       "75%       0.396790     0.555601     0.708050     0.281080     0.469292\n",
       "max       1.751740     2.421970     2.682040     1.811220     3.519750"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()[['feature0', 'feature1', 'feature2', 'feature3', 'feature4',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1194ead10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6AAAAEdCAYAAAASDgozAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAIAh/j8dgkBMrFbNTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11929a390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[feature_cols[:5]].describe().ix[1:,].plot(kind='bar', figsize=(16, 4), title=\"First five features\".title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "target_col = 'category'\n",
    "X_all = df[feature_cols]  # feature values for all students\n",
    "y_all = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3470, 2048)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3470,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split up the train and test data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "test_size = 0.3 # 30 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_size, random_state=0, stratify=y_all)\n",
    "\n",
    "# Split up the filepaths for comparison (useful for datamind benchmark)\n",
    "X_train_filepath, X_test_filepath, y_train_filepath, y_test_filepath = train_test_split(\n",
    "    df['filepath'], df.category.apply(cat_name), test_size=test_size, random_state=0, stratify=y_all)\n",
    "train_data = pd.DataFrame({'filepath': X_train_filepath, 'category': y_train_filepath})\n",
    "test_data = pd.DataFrame({'filepath': X_test_filepath, 'category': y_test_filepath})\n",
    "train_data.to_csv('data/kfood_train.txt', index=False)\n",
    "test_data.to_csv('data/kfood_test.txt', index=False)\n",
    "\n",
    "# Test to see that the train_test_split splits the filepaths the same way as the feature data\n",
    "np.array_equal(pd.merge(pd.DataFrame(X_train_filepath, columns=['filepath']), df, how='left', on='filepath')[feature_cols].values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2431, 2048), (1039, 2048))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2431,), (1039,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42739613327848625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1039./2431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datsci.eda import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>test_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bibimbab</th>\n",
       "      <td>150</td>\n",
       "      <td>64</td>\n",
       "      <td>0.299065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bossam</th>\n",
       "      <td>121</td>\n",
       "      <td>52</td>\n",
       "      <td>0.300578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bulgogi</th>\n",
       "      <td>128</td>\n",
       "      <td>55</td>\n",
       "      <td>0.300546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dakbokeumtang</th>\n",
       "      <td>120</td>\n",
       "      <td>51</td>\n",
       "      <td>0.298246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dakgalbi</th>\n",
       "      <td>144</td>\n",
       "      <td>61</td>\n",
       "      <td>0.297561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddukbokee</th>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>galbijjim</th>\n",
       "      <td>153</td>\n",
       "      <td>66</td>\n",
       "      <td>0.301370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hotteok</th>\n",
       "      <td>147</td>\n",
       "      <td>63</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japchae</th>\n",
       "      <td>135</td>\n",
       "      <td>58</td>\n",
       "      <td>0.300518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeon</th>\n",
       "      <td>94</td>\n",
       "      <td>40</td>\n",
       "      <td>0.298507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeyookbokkeum</th>\n",
       "      <td>116</td>\n",
       "      <td>49</td>\n",
       "      <td>0.296970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kimbab</th>\n",
       "      <td>152</td>\n",
       "      <td>65</td>\n",
       "      <td>0.299539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kimchi</th>\n",
       "      <td>89</td>\n",
       "      <td>38</td>\n",
       "      <td>0.299213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lagalbi</th>\n",
       "      <td>104</td>\n",
       "      <td>44</td>\n",
       "      <td>0.297297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nangmyun</th>\n",
       "      <td>145</td>\n",
       "      <td>62</td>\n",
       "      <td>0.299517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramen</th>\n",
       "      <td>83</td>\n",
       "      <td>35</td>\n",
       "      <td>0.296610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samgyetang</th>\n",
       "      <td>111</td>\n",
       "      <td>47</td>\n",
       "      <td>0.297468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samgyupsal</th>\n",
       "      <td>121</td>\n",
       "      <td>52</td>\n",
       "      <td>0.300578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sullungtang</th>\n",
       "      <td>135</td>\n",
       "      <td>58</td>\n",
       "      <td>0.300518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yookgyejang</th>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>0.303571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train  test  test_perc\n",
       "bibimbab         150    64   0.299065\n",
       "bossam           121    52   0.300578\n",
       "bulgogi          128    55   0.300546\n",
       "dakbokeumtang    120    51   0.298246\n",
       "dakgalbi         144    61   0.297561\n",
       "ddukbokee        105    45   0.300000\n",
       "galbijjim        153    66   0.301370\n",
       "hotteok          147    63   0.300000\n",
       "japchae          135    58   0.300518\n",
       "jeon              94    40   0.298507\n",
       "jeyookbokkeum    116    49   0.296970\n",
       "kimbab           152    65   0.299539\n",
       "kimchi            89    38   0.299213\n",
       "lagalbi          104    44   0.297297\n",
       "nangmyun         145    62   0.299517\n",
       "ramen             83    35   0.296610\n",
       "samgyetang       111    47   0.297468\n",
       "samgyupsal       121    52   0.300578\n",
       "sullungtang      135    58   0.300518\n",
       "yookgyejang       78    34   0.303571"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_counts_df = pd.concat([y_train.apply(cat_name).value_counts(), y_test.apply(cat_name).value_counts()], axis=1)\n",
    "split_counts_df.columns = ['train', 'test']\n",
    "split_counts_df['test_perc'] = split_counts_df.apply(lambda row: float(row.test) / row.sum(), axis=1)\n",
    "split_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+------+----------------+\n",
      "|               | train | test |   test_perc    |\n",
      "+---------------+-------+------+----------------+\n",
      "|    bibimbab   |  150  |  64  | 0.299065420561 |\n",
      "|     bossam    |  121  |  52  | 0.300578034682 |\n",
      "|    bulgogi    |  128  |  55  | 0.300546448087 |\n",
      "| dakbokeumtang |  120  |  51  | 0.298245614035 |\n",
      "|    dakgalbi   |  144  |  61  | 0.29756097561  |\n",
      "|   ddukbokee   |  105  |  45  |      0.3       |\n",
      "|   galbijjim   |  153  |  66  | 0.301369863014 |\n",
      "|    hotteok    |  147  |  63  |      0.3       |\n",
      "|    japchae    |  135  |  58  | 0.300518134715 |\n",
      "|      jeon     |   94  |  40  | 0.298507462687 |\n",
      "| jeyookbokkeum |  116  |  49  | 0.29696969697  |\n",
      "|     kimbab    |  152  |  65  | 0.299539170507 |\n",
      "|     kimchi    |   89  |  38  | 0.299212598425 |\n",
      "|    lagalbi    |  104  |  44  | 0.297297297297 |\n",
      "|    nangmyun   |  145  |  62  | 0.299516908213 |\n",
      "|     ramen     |   83  |  35  | 0.296610169492 |\n",
      "|   samgyetang  |  111  |  47  | 0.29746835443  |\n",
      "|   samgyupsal  |  121  |  52  | 0.300578034682 |\n",
      "|  sullungtang  |  135  |  58  | 0.300518134715 |\n",
      "|  yookgyejang  |   78  |  34  | 0.303571428571 |\n",
      "+---------------+-------+------+----------------+\n"
     ]
    }
   ],
   "source": [
    "pprint(split_counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Classifiers to try in Sklearn:\n",
    "\n",
    "- SVC\n",
    "- KNeighborsClassifier\n",
    "- RandomForestClassifier\n",
    "- LogisticRegression\n",
    "- GradientBoostingClassifier\n",
    "- AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test, description):\n",
    "    results = {'description': description}\n",
    "    \n",
    "    # Train\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    results['time_train'] = end - start\n",
    "\n",
    "    # Predict train\n",
    "    start = time.time()\n",
    "    y_hat = clf.predict(X_train)\n",
    "    end = time.time()\n",
    "    results['f1_score_train'] = f1_score(y_train.values, y_hat, average='micro')\n",
    "    results['time_predict_train'] = end - start\n",
    "\n",
    "    # Predict test\n",
    "    start = time.time()\n",
    "    y_hat = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    results['f1_score_test'] = f1_score(y_test.values, y_hat, average='micro')\n",
    "    results['time_predict_test'] = end - start\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=1.0, kernel='linear', gamma='auto')\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC linear kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='poly', degree=2, gamma='auto')\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC polynomial deg 2 kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='poly', degree=3, gamma='auto')\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC polynomial deg 3 kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='auto')\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC rbf kernel, one-vs-one\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='linear', gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC linear kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='poly', degree=2, gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC linear poly deg 2 kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='poly', degree=3, gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC linear poly deg 3 kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='rbf', gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"SVC rbf kernel, one-vs-rest\"))\n",
    "\n",
    "# K-Neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "clf = KNC(n_neighbors=3, weights='uniform')\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"KNeighbors, 3 neighbors\"))\n",
    "\n",
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "clf = RFC(n_estimators=10, max_depth=None, min_samples_split=2, n_jobs=2)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"RandomForest, 10 estimators\"))\n",
    "\n",
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty='l2', random_state=0, multi_class='ovr', n_jobs=4)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"LogisticRegression ovr\"))\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', random_state=0, multi_class='multinomial', solver='lbfgs', n_jobs=1)\n",
    "results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"LogisticRegression multinomial\"))\n",
    "\n",
    "# Tried boosting, but not such great results, so exclude from further analysis\n",
    "# # GradientBoostingClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "# clf = GBC(loss='deviance', learning_rate=0.1, n_estimators=100, max_depth=None, min_samples_split=2)\n",
    "# results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"GradientBoostingClassifier\"))\n",
    "\n",
    "# # AdaBoostClassifier\n",
    "# from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "# clf = ABC(SVC(C=1.0, kernel='linear', gamma='auto'), n_estimators=100, learning_rate=1.0, algorithm='SAMME')\n",
    "#results.append(train_predict(clf, X_train, y_train, X_test, y_test, \"AdaBoostClassifier w SVC linear kernel\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Results using f1_score with average='micro':\n",
    "\n",
    "                              description   f1_score_test  f1_score_train  time_predict_test  time_predict_train    time_train\n",
    "            SVC linear kernel, one-vs-one        0.794995        1.000000           3.811647            8.710620      6.530875\n",
    "  SVC polynomial deg 2 kernel, one-vs-one        0.271415        0.266557           4.560238           10.932422     19.331461\n",
    "  SVC polynomial deg 3 kernel, one-vs-one        0.064485        0.063348           4.647615           10.951944     19.621503\n",
    "               SVC rbf kernel, one-vs-one        0.704524        0.763472           4.424742           10.265058     12.673358\n",
    "           SVC linear kernel, one-vs-rest        0.769971        1.000000           9.859875           23.225768     14.141236\n",
    "SVC linear poly deg 2 kernel, one-vs-rest        0.721848        0.839572          12.610308           29.113087     16.113646\n",
    "SVC linear poly deg 3 kernel, one-vs-rest        0.726660        0.868367          12.953984           30.955226     17.060905\n",
    "              SVC rbf kernel, one-vs-rest        0.730510        0.830111          11.662916           27.549705     15.683099\n",
    "                  KNeighbors, 3 neighbors        0.619827        0.815714           7.049512           16.117123      0.267269\n",
    "              RandomForest, 10 estimators        0.457170        0.995475           0.015634            0.022134      0.934990\n",
    "               GradientBoostingClassifier        0.448508        1.000000           0.111043            0.270002   2495.067427\n",
    "   AdaBoostClassifier w SVC linear kernel        0.678537        0.781160         463.121845         1087.314692   2854.012287\n",
    "                   LogisticRegression ovr        0.793070        1.000000           0.009143            0.015798     16.777627\n",
    "           LogisticRegression multinomial        0.803657        1.000000           0.004691            0.009141      1.540244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# Re-run using just simple accuracy scores, in order to compare with retrain code in tensorflow/examples/image_retraining\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_predict2(clf, X_train, y_train, X_test, y_test, description):\n",
    "    results = {'description': description}\n",
    "    \n",
    "    # Train\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    results['time_train'] = end - start\n",
    "\n",
    "    # Predict train\n",
    "    start = time.time()\n",
    "    y_hat = clf.predict(X_train)\n",
    "    end = time.time()\n",
    "    results['accuracy_train'] = accuracy_score(y_train.values, y_hat)\n",
    "    results['time_predict_train'] = end - start\n",
    "\n",
    "    # Predict test\n",
    "    start = time.time()\n",
    "    y_hat = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    results['accuracy_test'] = accuracy_score(y_test.values, y_hat)\n",
    "    results['time_predict_test'] = end - start\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=1.0, kernel='linear', gamma='auto')\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC linear kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='poly', degree=2, gamma='auto')\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC polynomial deg 2 kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='poly', degree=3, gamma='auto')\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC polynomial deg 3 kernel, one-vs-one\"))\n",
    "\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='auto')\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC rbf kernel, one-vs-one\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='linear', gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC linear kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='poly', degree=2, gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC linear poly deg 2 kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='poly', degree=3, gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC linear poly deg 3 kernel, one-vs-rest\"))\n",
    "\n",
    "clf = sklearn.multiclass.OneVsRestClassifier(SVC(C=1.0, kernel='rbf', gamma='auto'), n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"SVC rbf kernel, one-vs-rest\"))\n",
    "\n",
    "# K-Neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "clf = KNC(n_neighbors=3, weights='uniform')\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"KNeighbors, 3 neighbors\"))\n",
    "\n",
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "clf = RFC(n_estimators=10, max_depth=None, min_samples_split=2, n_jobs=2)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"RandomForest, 10 estimators\"))\n",
    "\n",
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty='l2', random_state=0, multi_class='ovr', n_jobs=4)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"LogisticRegression ovr\"))\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', random_state=0, multi_class='multinomial', solver='newton-cg', n_jobs=1)\n",
    "results.append(train_predict2(clf, X_train, y_train, X_test, y_test, \"LogisticRegression multinomial\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy_test  accuracy_train                     description  \\\n",
      "0       0.803657               1  LogisticRegression multinomial   \n",
      "\n",
      "   time_predict_test  time_predict_train  time_train  \n",
      "0           0.008209            0.010171   10.576213  \n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "    accuracy_test  accuracy_train                                description  time_predict_test  time_predict_train  time_train\n",
    "0        0.794995        1.000000              SVC linear kernel, one-vs-one           3.966444            9.055261    6.557868 \n",
    "1        0.271415        0.266557    SVC polynomial deg 2 kernel, one-vs-one           4.838109           11.241315   20.264152 \n",
    "2        0.064485        0.063348    SVC polynomial deg 3 kernel, one-vs-one           4.709020           11.161063   20.114124 \n",
    "3        0.704524        0.763472                 SVC rbf kernel, one-vs-one           4.518843           10.798448   12.761727 \n",
    "4        0.769971        1.000000             SVC linear kernel, one-vs-rest          10.246530           24.071269   14.418401 \n",
    "5        0.721848        0.839572  SVC linear poly deg 2 kernel, one-vs-rest          12.586333           29.298426   16.180739 \n",
    "6        0.726660        0.868367  SVC linear poly deg 3 kernel, one-vs-rest          12.762013           30.456582   17.197990 \n",
    "7        0.730510        0.830111                SVC rbf kernel, one-vs-rest          11.545363           27.218193   15.499681 \n",
    "8        0.619827        0.815714                    KNeighbors, 3 neighbors           6.958227           16.025329    0.264954 \n",
    "9        0.457170        0.996709                RandomForest, 10 estimators           0.140045            0.158466    0.558396 \n",
    "10       0.793070        1.000000                     LogisticRegression ovr           0.005958            0.010534   18.181948\n",
    "11       0.803657        1.000000             LogisticRegression multinomial           0.008209            0.010171   10.576213"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "## Fine-tune SVC linear kernel and Logistic Regression ovr and multinomial models using logloss/cross entropy error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each iteration time(secs): 266.620\n",
      "0.796920115496 {'kernel': 'rbf', 'C': 17.5}\n",
      "Each iteration time(secs): 262.910\n",
      "iteration 2\n",
      "Each iteration time(secs): 257.520\n",
      "iteration 1\n",
      "iteration 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.grid_search import GridSearchCV as GSCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVC linear kernel\n",
    "clf_svc = SVC(gamma='auto', probability=True)\n",
    "\n",
    "best_score = None\n",
    "best_params = None\n",
    "for i in xrange(3):\n",
    "    if i < 3 or i % 10 == 0:\n",
    "\tprint \"iteration {}\".format(i)\n",
    "\tstart = time.time()\n",
    "    gs_clf = GSCV(\n",
    "\tclf_svc,\n",
    "\t{'kernel':['rbf'], 'C':[16, 16.5, 17, 17.5, 18]},\n",
    "\tscoring='log_loss',\n",
    "\tcv=5,\n",
    "\tn_jobs=4)\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    _score = accuracy_score(y_test, gs_clf.predict(X_test))\n",
    "    if best_score is None or best_score < _score:\n",
    "\tbest_score = _score\n",
    "\tbest_params = {\n",
    "\t    'C': gs_clf.best_estimator_.C,\n",
    "\t    'kernel': gs_clf.best_estimator_.kernel}\n",
    "    if i < 3:\n",
    "\tend = time.time()    \n",
    "\tprint \"Each iteration time(secs): {:.3f}\".format(end - start)\n",
    "\t\n",
    "print best_score, best_params"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "{'kernel':['linear', 'rbf'], 'C':[10.0, 1.0, .1, .01]},\n",
    "Each iteration time(secs): 524.065\n",
    "Each iteration time(secs): 522.901\n",
    "iteration 2\n",
    "Each iteration time(secs): 525.689\n",
    "iteration 1\n",
    "iteration 0\n",
    "0.789220404235 {'kernel': 'rbf', 'C': 10.0}\n",
    "\n",
    "{'kernel':['rbf'], 'C':[5.0, 10.0, 15.0]},\n",
    "iteration 0\n",
    "Each iteration time(secs): 175.648\n",
    "iteration 1\n",
    "Each iteration time(secs): 176.097\n",
    "iteration 2\n",
    "Each iteration time(secs): 174.976\n",
    "0.793070259865 {'kernel': 'rbf', 'C': 15.0}\n",
    "\n",
    "{'kernel':['rbf'], 'C':[20, 30, 40]},\n",
    "iteration 0\n",
    "Each iteration time(secs): 168.852\n",
    "iteration 1\n",
    "Each iteration time(secs): 168.142\n",
    "iteration 2\n",
    "Each iteration time(secs): 168.903\n",
    "0.799807507218 {'kernel': 'rbf', 'C': 20}\n",
    "\n",
    "{'kernel':['rbf'], 'C':[17, 19, 21, 23]},\n",
    "print best_score, best_params\n",
    "iteration 0\n",
    "Each iteration time(secs): 209.840\n",
    "iteration 1\n",
    "Each iteration time(secs): 204.861\n",
    "iteration 2\n",
    "Each iteration time(secs): 204.436\n",
    "0.795957651588 {'kernel': 'rbf', 'C': 17}\n",
    "\n",
    "{'kernel':['rbf'], 'C':[16, 16.5, 17, 17.5, 18]},\n",
    "iteration 0\n",
    "Each iteration time(secs): 257.520\n",
    "iteration 1\n",
    "Each iteration time(secs): 262.910\n",
    "iteration 2\n",
    "Each iteration time(secs): 266.620\n",
    "0.796920115496 {'kernel': 'rbf', 'C': 17.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# Retrain SVC with all training data, and get accuracy on test data\n",
    "\n",
    "clf_svc = SVC(kernel='rbf', C=17.5, gamma='auto', probability=True)\n",
    "clf_svc.fit(X_train, y_train)\n",
    "y_hat_svc = clf_svc.predict(X_test)\n",
    "clf_svc_accuracy = accuracy_score(y_test.values, y_hat_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "clf_svc_results = pd.DataFrame({'y_hat': pd.Series(y_hat_svc).apply(cat_name).values, 'y_true': y_test.apply(cat_name).values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         y_hat       y_true\n",
       "0      bulgogi      bulgogi\n",
       "1      japchae      japchae\n",
       "2    ddukbokee    ddukbokee\n",
       "3  sullungtang  sullungtang\n",
       "4    ddukbokee    ddukbokee"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79692011549566888"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc_results.apply(lambda row: row.y_hat == row.y_true, axis=1).sum() / float(clf_svc_results.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79692011549566888"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "clf_svc_results.to_csv('data/sklearn_svc_test_results.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.797882579403 {'C': 0.27, 'tol': 1e-08}\n",
      "\n",
      "iteration 2\n",
      "Each iteration time(secs): 881.821\n",
      "iteration 1\n",
      "Each iteration time(secs): 883.683iteration 0\n",
      "Each iteration time(secs): 898.157"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.grid_search import GridSearchCV as GSCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression ovr\n",
    "\n",
    "clf_lr = LogisticRegression(\n",
    "    penalty='l2', random_state=0, multi_class='ovr', n_jobs=4)\n",
    "\n",
    "best_score = None\n",
    "best_params = None\n",
    "for i in xrange(3):\n",
    "    if i < 3 or i % 10 == 0:\n",
    "\tprint \"iteration {}\".format(i)\n",
    "\tstart = time.time()\n",
    "    gs_clf = GSCV(\n",
    "\tclf_lr,\n",
    "\t{'tol': [1e-8, 1e-9, 1e-10], 'C': [.27, .3, .33]},\n",
    "\tscoring='log_loss',\n",
    "\tcv=5,\n",
    "\tn_jobs=1)\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    _score = accuracy_score(y_test, gs_clf.predict(X_test))\n",
    "    if best_score is None or best_score < _score:\n",
    "\tbest_score = _score\n",
    "\tbest_params = {\n",
    "\t    'C': gs_clf.best_estimator_.C,\n",
    "\t    'tol': gs_clf.best_estimator_.tol}\n",
    "    if i < 3:\n",
    "\tend = time.time()    \n",
    "\tprint \"Each iteration time(secs): {:.3f}\".format(end - start)\n",
    "\t\n",
    "print best_score, best_params"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "{'tol': [0.0001, 0.001, 0.00001], 'C': [10.0, 1.0, .1, .01]},\n",
    "iteration 0\n",
    "Each iteration time(secs): 693.701\n",
    "iteration 1\n",
    "Each iteration time(secs): 694.704\n",
    "iteration 2\n",
    "Each iteration time(secs): 687.939\n",
    "0.804619826756 {'C': 0.1, 'tol': 1e-05}\n",
    "\n",
    "{'tol': [0.000001, 0.00001, 0.00005], 'C': [.3, .1, .07]},\n",
    "iteration 0\n",
    "Each iteration time(secs): 546.397\n",
    "iteration 1\n",
    "Each iteration time(secs): 548.634\n",
    "iteration 2\n",
    "Each iteration time(secs): 557.571\n",
    "0.796920115496 {'C': 0.3, 'tol': 1e-06}\n",
    "\n",
    "{'tol': [0.000001, 0.0000001, 0.00000001], 'C': [.3, .4, .5]},\n",
    "iteration 0\n",
    "Each iteration time(secs): 840.295\n",
    "iteration 1\n",
    "Each iteration time(secs): 849.685\n",
    "iteration 2\n",
    "Each iteration time(secs): 812.325\n",
    "0.796920115496 {'C': 0.3, 'tol': 1e-08}\n",
    "\n",
    "{'tol': [1e-8, 1e-9, 1e-10], 'C': [.27, .3, .33]},\n",
    "iteration 0\n",
    "Each iteration time(secs): 898.157\n",
    "iteration 1\n",
    "Each iteration time(secs): 883.683\n",
    "iteration 2\n",
    "Each iteration time(secs): 881.821\n",
    "0.797882579403 {'C': 0.27, 'tol': 1e-08}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# Retrain LogisticRegression ovr with all training data and get accuracy on test data\n",
    "\n",
    "clf_lr = LogisticRegression(C=0.27, tol=1e-08,\n",
    "    penalty='l2', random_state=0, multi_class='ovr', n_jobs=8)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "y_hat_lr = clf_lr.predict(X_test)\n",
    "clf_lr_accuracy = accuracy_score(y_test.values, y_hat_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79788257940327234"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "clf_lr_results = pd.DataFrame({'y_hat': pd.Series(y_hat_lr).apply(cat_name).values, 'y_true': y_test.apply(cat_name).values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "clf_lr_results.to_csv('data/sklearn_lr_test_results.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "weird bug: \n",
    "running GridCV w LogisticRegression with n_jobs > 1 for LogisticRegression while n_jobs > 1 for GridCV causes cpu hang\n",
    "Not sure if it's only for this version, or only for python 2.7.x\n",
    "https://github.com/scikit-learn/scikit-learn/issues/3605\n",
    "ovr: Keep LogisticRegression n_jobs > 1, but GridCV n_jobs = 1\n",
    "multinomial: both n_jobs=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.806544754572 {'C': 0.2, 'max_iter': 300, 'tol': 0.0001}\n",
      "\n",
      "iteration 2\n",
      "Each iteration time(secs): 158.727\n",
      "iteration 1\n",
      "Each iteration time(secs): 158.391iteration 0\n",
      "Each iteration time(secs): 158.433"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.grid_search import GridSearchCV as GSCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression multinomial\n",
    "\n",
    "clf_lr2 = LogisticRegression(\n",
    "    penalty='l2', random_state=0, multi_class='multinomial', solver='lbfgs', n_jobs=1)\n",
    "    \n",
    "best_score = None\n",
    "best_params = None\n",
    "for i in xrange(3):\n",
    "    if i < 3 or i % 10 == 0:\n",
    "\tprint \"iteration {}\".format(i)\n",
    "\tstart = time.time()\n",
    "    gs_clf = GSCV(\n",
    "\tclf_lr2,\n",
    "\t{'tol': [0.0001], 'C': [.17, .2, .23], 'max_iter': [270, 300, 350]},\n",
    "\tscoring='log_loss',\n",
    "\tcv=5,\n",
    "\tn_jobs=1)\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    _score = accuracy_score(y_test, gs_clf.predict(X_test))\n",
    "    if best_score is None or best_score < _score:\n",
    "\tbest_score = _score\n",
    "\tbest_params = {\n",
    "\t    'C': gs_clf.best_estimator_.C,\n",
    "\t    'max_iter': gs_clf.best_estimator_.max_iter,\n",
    "\t    'tol': gs_clf.best_estimator_.tol}\n",
    "    if i < 3:\n",
    "\tend = time.time()    \n",
    "\tprint \"Each iteration time(secs): {:.3f}\".format(end - start)\n",
    "\t\n",
    "print best_score, best_params"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "{'tol': [0.0001, 0.001, 0.00001], 'C': [10.0, 1.0, .1, .01], 'max_iter': [100, 50, 150]}\n",
    "iteration 0\n",
    "Each iteration time(secs): 253.191\n",
    "iteration 1\n",
    "Each iteration time(secs): 249.160\n",
    "iteration 2\n",
    "Each iteration time(secs): 248.184\n",
    "0.799807507218 {'C': 0.1, 'max_iter': 150, 'tol': 0.0001}\n",
    "\n",
    "{'tol': [0.0001, 0.0003, 0.00008], 'C': [.07, .1, .2], 'max_iter': [125, 150, 200]},\n",
    "iteration 0\n",
    "Each iteration time(secs): 252.166\n",
    "iteration 1\n",
    "Each iteration time(secs): 250.710\n",
    "iteration 2\n",
    "Each iteration time(secs): 250.147\n",
    "0.809432146295 {'C': 0.2, 'max_iter': 200, 'tol': 0.0001}\n",
    "\n",
    "{'tol': [0.0001, 0.00015, 0.00009], 'C': [.15, .2, .3], 'max_iter': [250, 300, 400]},\n",
    "iteration 0\n",
    "Each iteration time(secs): 487.091\n",
    "iteration 1\n",
    "Each iteration time(secs): 488.607\n",
    "iteration 2\n",
    "Each iteration time(secs): 486.965\n",
    "0.806544754572 {'C': 0.2, 'max_iter': 300, 'tol': 0.0001}\n",
    "\n",
    "{'tol': [0.0001], 'C': [.17, .2, .23], 'max_iter': [270, 300, 350]},\n",
    "iteration 0\n",
    "Each iteration time(secs): 158.433\n",
    "iteration 1\n",
    "Each iteration time(secs): 158.391\n",
    "iteration 2\n",
    "Each iteration time(secs): 158.727\n",
    "0.806544754572 {'C': 0.2, 'max_iter': 300, 'tol': 0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# Retrain LogisticRegression multinomial with all training data and get accuracy on test\n",
    "\n",
    "clf_lr2 = LogisticRegression(C=0.2, max_iter=300, tol=0.0001,\n",
    "    penalty='l2', random_state=0, multi_class='multinomial', solver='lbfgs', n_jobs=1)\n",
    "clf_lr2.fit(X_train, y_train)\n",
    "y_hat_lr2 = clf_lr2.predict(X_test)\n",
    "clf_lr2_accuracy = accuracy_score(y_test.values, y_hat_lr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065447545717036"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr2_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "clf_lr2_results = pd.DataFrame({'y_hat': pd.Series(y_hat_lr2).apply(cat_name).values, 'y_true': y_test.apply(cat_name).values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065447545717036"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr2_results.apply(lambda row: row.y_hat == row.y_true, axis=1).sum() / float(clf_lr2_results.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "clf_lr2_results.to_csv('data/sklearn_lr2_test_results.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Run with tensorflow retrain final layer from within `tensorflow/examples/image_retraining` -> `tensorflow_retrain`\n",
    "\n",
    "```\n",
    "time python retrain.py --image_dir kfood --output_graph ./kfood_graph.pb --output_labels ./kfood_output_labels.txt --how_many_training_steps 5000 --learning_rate 0.01 --testing_percentage 25 --validation_percentage 5 --train_batch_size 200 --noflip_left_right --random_crop 0 --random_scale 0 --random_brightness 0\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "source": [
    "Summary of results for tensorflow retraining last layer\n",
    "train_accuracy and valid_accuracy correspond only to the batch in the last training step\n",
    "I tried running random_crop random_scale and random_brightness != 0, but had to cancel those jobs because they were about to fry my laptop\n",
    "* Running on gpu install of tensorflow - doesn't make much difference\n",
    "\n",
    "\n",
    "training_steps learning_rate train_batch_size flip_left_right random_crop random_scale random_brightness valid_perc test_perc train_accuracy valid_accuracy test_accuracy runtime\n",
    "4000           0.01          100              no              0           0            0                 20         20         92.0           73.0           76.8          NA\n",
    "8000           0.01          100              no              0           0            0                 20         20         98.0           81.0           79.2          NA\n",
    "12000          0.01          100              no              0           0            0                 20         20         100.0          74.0           81.8          NA\n",
    "16000          0.01          100              no              0           0            0                 20         20         99.0           77.0           74.8          18m10.696s\n",
    "4000           0.1           100              no              0           0            0                 20         20         100.0          75.0           78.4          4m59.003s *\n",
    "8000           0.1           100              no              0           0            0                 20         20         100.0          80.0           78.4          9m34.358s *\n",
    "8000           0.05          100              no              0           0            0                 20         20         100.0          82.0           79.8          9m48.046s *\n",
    "12000          0.05          100              no              0           0            0                 20         20         100.0          80.0           75.6          14m56.545s *\n",
    "4000           0.01          200              no              0           0            0                 20         20         95.0           80.0           81.0          8m18.477s\n",
    "4500           0.01          200              no              0           0            0                 20         20         91.5           79.0           81.6          9m24.027s\n",
    "4750           0.01          200              no              0           0            0                 20         20         95.5           83.0           80.8          10m49.686s\n",
    "4775           0.01          200              no              0           0            0                 20         20         94.0           84.0           80.4          9m37.835s\n",
    "4780           0.01          200              no              0           0            0                 20         20         88.5           79.0           80.4          10m4.653s\n",
    "4790           0.01          200              no              0           0            0                 20         20         96.0           67.0           80.8          10m2.089s\n",
    "4800           0.01          200              no              0           0            0                 20         20         93.0           70.0           80.0          10m5.406s\n",
    "4810           0.01          200              no              0           0            0                 20         20         97.0           67.0           81.2          9m59.352s\n",
    "4850           0.01          200              no              0           0            0                 20         20         91.5           70.0           76.0          10m48.614s\n",
    "4900           0.01          200              no              0           0            0                 20         20         93.0           77.0           81.2          10m46.906s\n",
    "5000           0.01          200              no              0           0            0                 20         20         95.0           79.0           82.4          10m20.320s\n",
    "5500           0.01          200              no              0           0            0                 20         20         96.5           80.0           80.6          11m19.920s\n",
    "6000           0.01          200              no              0           0            0                 20         20         95.5           76.0           80.2          11m59.707s\n",
    "8000           0.01          200              no              0           0            0                 20         20         95.0           85.0           79.4          16m23.208s\n",
    "12000          0.01          200              no              0           0            0                 20         20         99.0           75.0           77.8          208m48.420s\n",
    "4000           0.01          300              no              0           0            0                 20         20         94.3           77.0           81.2          12m21.572s\n",
    "8000           0.01          300              no              0           0            0                 20         20         98.0           86.0           78.2          31m41.840s\n",
    "5000           0.02          200              no              0           0            0                 20         20         98.5           77.0           81.0          10m35.363s\n",
    "5000           0.008         200              no              0           0            0                 20         20         94.0           79.0           79.2          10m26.045s\n",
    "5000           0.01          225              no              0           0            0                 20         20         94.7           81.0           78.8          11m19.542s\n",
    "5000           0.01          180              no              0           0            0                 20         20         95.0           73.0           82.4          9m14.935s\n",
    "5000           0.01          190              no              0           0            0                 20         20         96.3           81.0           80.8          9m56.740s\n",
    "4800           0.01          225              no              0           0            0                 5          25         91.1           82.0           78.4          10m45.684s\n",
    "5000           0.01          225              no              0           0            0                 5          25         93.3           68.0           75.4          11m9.589s\n",
    "\n",
    "\n",
    "\n",
    "5000           0.01          200              no              0           0            0                 5          25         92.5           74.0           77.4          10m26.148s\n",
    "5000           0.01          175              no              0           0            0                 5          25         92.6           74.0           80.2          8m51.950s\n",
    "5500           0.01          175              no              0           0            0                 5          25         95.4           74.0           76.0          10m28.258s\n",
    "5800           0.01          175              no              0           0            0                 5          25         \n",
    "6000           0.01          175              no              0           0            0                 5          25         94.3           69.0           81.4          11m11.572sp\n",
    "6500           0.01          175              no              0           0            0                 5          25         95.4           75.0           75.6          12m32.043s\n",
    "7000           0.01          175              no              0           0            0                 5          25         96.6           76.0           79.2          13m23.146s\n",
    "5000           0.01          150              no              0           0            0                 5          25         95.3           80.0           77.8          7m46.747s\n",
    "5000           0.01          125              no              0           0            0                 5          25         98.4           77.0           78.2          6m35.836s\n",
    "5000           0.01          100              no              0           0            0                 5          25         96.0           67.0           81.2          5m25.950s\n",
    "6000           0.01          100              no              0           0            0                 5          25         96.0           78.0           78.8          6m33.281s\n",
    "7000           0.01          100              no              0           0            0                 5          25         96.0           72.0           79.6          7m39.502s\n",
    "8000           0.01          100              no              0           0            0                 5          25         97.0           78.0           79.8          8m39.124s\n",
    "10000          0.01          100              no              0           0            0                 5          25         97.0           71.0           78.6          10m49.417s\n",
    "\n",
    "\n",
    "\n",
    "5500           0.01          200              no              0           0            0                 5          25         96.5           73.0           76.8          11m38.637s\n",
    "6000           0.01          200              no              0           0            0                 5          25         96.0           66.0           79.6          13m32.454s\n",
    "7000           0.01          200              no              0           0            0                 5          25         94.5           67.0           78.6          15m12.233s\n",
    "8000           0.01          200              no              0           0            0                 5          25         96.5           75.0           78.4          17m3.484s\n",
    "10000          0.01          200              no              0           0            0                 5          25         97.5           73.0           78.0          22m6.034s\n",
    "5000           0.1           200              no              0           0            0                 5          25         100.0          65.0           76.8          11m4.966s\n",
    "4000           0.1           200              no              0           0            0                 5          25         100.0          81.0           80.4          8m47.910s\n",
    "3700           0.1           200              no              0           0            0                 5          25         100.0          74.0           76.8          9m42.065s\n",
    "3600           0.1           200              no              0           0            0                 5          25         100.0          77.0           78.8          7m37.593s\n",
    "3500           0.11          200              no              0           0            0                 5          25         100.0          83.0           78.2          7m35.430s\n",
    "3500           0.1           200              no              0           0            0                 5          25         100.0          78.0           81.6          7m19.125s\n",
    "3500           0.09          200              no              0           0            0                 5          25         100.0          74.0           78.8          7m48.905s\n",
    "3450           0.1           200              no              0           0            0                 5          25         100.0          80.0           79.2          7m58.816s\n",
    "3400           0.1           200              no              0           0            0                 5          25         100.0          76.0           82.0          9m5.169sp\n",
    "3300           0.1           200              no              0           0            0                 5          25         100.0          71.0           77.4          7m1.023s\n",
    "3000           0.1           200              no              0           0            0                 5          25         100.0          73.0           77.2          6m44.807s\n",
    "3500           0.1           225              no              0           0            0                 5          25         100.0          74.0           79.8          8m25.868s\n",
    "3500           0.1           235              no              0           0            0                 5          25         100.0          82.0           80.6          8m42.936s\n",
    "3500           0.1           245              no              0           0            0                 5          25         100.0          74.0           76.6          9m6.938s\n",
    "3500           0.1           250              no              0           0            0                 5          25         100.0          75.0           81.8          9m19.626s\n",
    "3500           0.1           255              no              0           0            0                 5          25         100.0          70.0           80.8          8m57.075s\n",
    "3500           0.1           265              no              0           0            0                 5          25         100.0          79.0           77.4          NA\n",
    "3500           0.1           275              no              0           0            0                 5          25         99.6           73.0           76.4          10m9.105s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "# Run again using final settings, and store log, to create plot of decreasing cross entropy and increasing accuracy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "name": "kfood.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
